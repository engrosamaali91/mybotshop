<!DOCTYPE html>
<html lang="en">
 <head>
  <meta charset="utf-8"/>
  <meta content="width=device-width, initial-scale=1.0" name="viewport"/>
  <title>
    Digital Twin-Driven Safety Protocol Development for HRI in German Retail Stores
  </title>
  <style>
    body {
        font-family: Arial, sans-serif;
        line-height: 1.6;
        color: #333;
        margin: 0;
        padding: 0;
        background-color: #f4f4f4;
    }
    .container {
        width: 80%;
        margin: auto;
        overflow: hidden;
    }
    .header, .footer {
        background: #333;
        color: #fff;
        padding: 20px 0;
        text-align: center;
    }
    .main-content {
        background: #fff;
        padding: 20px;
        margin-bottom: 20px;
    }
    h1, h3, h4 {
        color: #34a734;
    }
    .note, .warning, .important {
        background: #e7f3fe;
        border-left: 6px solid #2196F3;
        padding: 10px;
        margin: 10px 0;
    }
    .warning {
        background: #ffebee;
        border-left: 6px solid #f44336;
    }
    .important {
        background: #fff3e0;
        border-left: 6px solid #ff9800;
    }
    code {
        background: #f4f4f4;
        padding: 2px 4px;
        border-radius: 4px;
    }
    pre {
        background: #f4f4f4;
        padding: 10px;
        border-radius: 4px;
        overflow: auto;
    }
    a {
        color: #2196F3;
        text-decoration: none;
    }
    a:hover {
        text-decoration: underline;
    }
    img {
        max-width: 100%;
        height: auto;
        margin-bottom: 20px;
        margin-top: 10px;

    }
    table {
        /* border-collapse: separate; */
        border-spacing: 15px; /* Adds spacing between columns */
        width: 100%;
    }
  </style>
 </head>

 <body>
    <div class="container">
        <div class="main-content">
            <h1>Digital Twin-Driven Safety Protocol Development for HRI in German Retail Stores</h1>
            <img src="https://raw.githubusercontent.com/MYBOTSHOP/media/refs/heads/main/thesis/dw/nl/workflow.webp" alt="Workflow">
            <p>Autonomous mobile robots are becoming increasingly intelligent through the integration of Artificial Intelligence (AI). These robots are now capable of making real-time decisions, such as determining optimal paths, navigating around obstacles, and dynamically choosing new routes. With advanced sensors like LiDAR and cameras, robots can detect and respond to both stationary and moving objects, ensuring the safety of people, themselves, and the surrounding environment.</p>
            <p>However, to operate safely and effectively, robots must adhere to strict safety protocols and comply with data protection regulations when interacting with humans. This is crucial to minimize risks, especially when deploying autonomous robots in settings such as retail stores or warehouses. Without thorough testing, there is a risk of accidents, injuries, or inventory damage. As a result, authorities have established safety regulations to ensure that robots are designed with compliance in mind.</p>
            <p>To address these challenges, MYBOTSHOP is investing significant time and resources into training students to test and validate safety protocols and data protection policies for both new and existing robots within simulation environments. These simulated tests ensure that robots can be safely deployed in real-world scenarios without jeopardizing human lives or privacy.</p>

            <h2>Comparison of Simulation Environments</h2>
            <img src="https://raw.githubusercontent.com/MYBOTSHOP/media/refs/heads/main/thesis/dw/nl/SE.webp" alt="Simulation Environments">
            <p>Testing autonomous robots in simulation environments is essential to evaluate their performance under both expected and unexpected conditions. This raises an important question: <strong>Which simulation environment is best for testing diverse scenarios?</strong></p>
            <p>To answer this, let’s compare three prominent simulation platforms: <strong>Gazebo Classic</strong>, <strong>Gazebo Fortress</strong>, and <strong>NVIDIA Isaac Sim</strong> (developed by Omniverse). Each platform has unique strengths and limitations, as highlighted in the <strong>comparison chart above</strong>.</p>
            <ul>
                <li><strong>Gazebo Classic</strong> offers ease of environment setup and a fast simulation speed but lacks support for high-definition simulations and crowd animation. It is a reliable choice for basic ROS2 integration without requiring high-end hardware.</li>
                <li><strong>Gazebo Fortress</strong> improves on crowd animation and introduces high-definition simulation capabilities. However, it is more resource-intensive and less user-friendly in terms of built-in plugins.</li>
                <li><strong>NVIDIA Isaac Sim</strong> stands out for its high-fidelity simulation and reinforcement learning support, making it ideal for advanced robotics applications. However, it demands high processing power and has a steeper learning curve for ROS2 integration.</li>
            </ul>
            <p>As illustrated in the <strong>image above</strong>, Gazebo Classic excels in simplicity, while NVIDIA Isaac Sim leads in advanced simulation capabilities. Choosing the right platform depends on your project's specific requirements, such as simulation fidelity or hardware limitations.</p>

            <h3>Observations on NVIDIA Isaac Sim for Simulation</h3>
            <p>NVIDIA Isaac Sim is a cutting-edge simulation platform that serves dual purposes: simulation testing and reinforcement learning. In Omni Isaac Gym, robots can be trained effectively for complex tasks. However, while Isaac Sim offers many advantages, as highlighted in the comparison table, it may not always be the best solution for simulations as a test bench.</p>

            <h4>Pros of Isaac Sim:</h4>
            <ul>
                <li>High-definition, realistic 3D scenes for immersive simulations.</li>
                <li>Integration with reinforcement learning frameworks for advanced robotic training.</li>
                <li>Built-in examples like Nova Carter robot navigation in warehouse environments.</li>
            </ul>

            <h4>Cons of Isaac Sim:</h4>
            <ul>
                <li>Requires high processing power, leading to potential lag in real-time applications.</li>
                <li>Challenges in adapting custom robots and environments, especially with configuring TF for parent-child relations.</li>
                <li>Slower map updates in RViz2, making real-time obstacle detection less reliable.</li>
            </ul>

            <h3>Real-World Test: Navigation in a Warehouse Environment</h3>
            <div  style="text-align: center;">
                <img src="https://media.githubusercontent.com/media/NVIDIA-ISAAC-ROS/.github/main/resources/isaac_ros_docs/robots/nova_carter/nova_carter_diagram_front_left.png" alt="NOVA Carter Robot">
            </div>
            <p  style="text-align: center;">
                <a href="https://media.githubusercontent.com/media/NVIDIA-ISAAC-ROS/.github/main/resources/isaac_ros_docs/robots/nova_carter/nova_carter_diagram_front_left.png" target="_blank">
                    <em>NOVA Carter Robot navigating a warehouse environment</em>
                </a>
            </p>
            <p>In our observations, we tested the <strong>Nova Carter robot</strong>, as shown in the image above, for navigation in a small warehouse environment using Isaac Sim. The robot, equipped with 2D and 3D LiDAR, fisheye, and depth cameras, was tasked to navigate static and dynamic obstacles.</p>

            <h4>Static Obstacle Navigation (Scene 1):</h4>
            <p>The image below depicts Isaac Sim and RViz2 side-by-side, with the robot planning a path around a static object in the warehouse. While the high-definition scene enhances realism, the robot experiences noticeable lag due to the computational demand of the graphics.</p>
            
            <div  style="text-align: center;">
                <img src="https://raw.githubusercontent.com/MYBOTSHOP/media/refs/heads/main/thesis/dw/carter_navigation.webp" alt="Scene 1: Navigation around static obstacles">
            </div>

            <h4>Dynamic Obstacle Detection (Scene 2):</h4>
            <p>For dynamic obstacles, such as a person walking through the environment, the simulation struggled to update the map in real-time. By the time the person was detected and the map updated in RViz2, the person had already moved forward, leaving outdated occupancy marks. This delay compromises the reliability of real-time obstacle detection, an issue tied to the simulation and less likely to occur in real-world scenarios.</p>
            <div  style="text-align: center;">
                <img src="https://raw.githubusercontent.com/MYBOTSHOP/media/refs/heads/main/thesis/dw/carter_with_human.webp" alt="Scene 2: Dynamic obstacle detection">
            </div>

            <h3>Tradeoff: Graphics vs. Speed</h3>
            <p>Isaac Sim’s high graphics quality comes at the cost of simulation speed, as shown in the image above. This tradeoff poses challenges when trying to create a digital twin of a realistic environment for algorithm testing. A digital twin must ensure safety protocols and accurate real-time processing. When the simulation platform itself becomes a bottleneck, it may be prudent to switch to alternatives like <strong>Gazebo</strong>, which can provide simpler scenes but better support for real-time algorithm testing without compromising safety.</p>

            <h3>Challenges with Isaac Sim for Custom Robots</h3>
            <p>Another critical challenge is adapting Isaac Sim nodes for custom robots and environments. For instance, configuring TF for custom robots often leads to issues with Isaac Sim’s built-in nodes failing to recognize parent-child relationships, causing delinked transforms. For example, the image below shows proper links with parent and child frames.</p>
            <img src="https://raw.githubusercontent.com/MYBOTSHOP/media/refs/heads/main/thesis/dw/nl/TFs.webp" alt="Transforms">
            <p>Isaac Sim provides several ROS2 nodes for handling TF transforms and odometry, such as:</p>
            <ul>
                <li><strong>TF Publisher</strong> for sensors and full articulation trees.</li>
                <li><strong>Raw TF Publisher</strong> for individual transforms.</li>
                <li><strong>Odometry Publisher</strong> for robot movement tracking.</li>
            </ul>
            <p>These nodes can be visualized in the Isaac Sim viewport for better debugging. However, the overhead in adapting and troubleshooting these nodes can be time-consuming.</p>
            <img src="https://docs.omniverse.nvidia.com/isaacsim/latest/_images/isaac_tutorial_ros2_odometry_graph_final.png" alt="Isaac Sim Nodes">
    
            <p  style="text-align: center;">
                <a href="https://docs.omniverse.nvidia.com/isaacsim/latest/_images/isaac_tutorial_ros2_odometry_graph_final.png" target="_blank">
                    <em>Isaac Sim Nodes</em>
                </a>
            </p>
            <h3>Recommendations</h3>
            <p>While Isaac Sim is an excellent platform for high-fidelity simulations, it is not always ideal for scenarios requiring speed and efficiency. For testing safety protocols or creating realistic digital twins, alternatives like Gazebo might offer a more balanced solution. High-definition graphics are secondary to the ability to reliably test algorithms under realistic constraints.</p>
        
            
            <h2>Why Gazebo Classic Can Do the Job Too</h2>
            <p>Gazebo Classic is a straightforward and reliable simulation platform for robotics. Unlike NVIDIA Isaac Sim, which demands high processing power, Gazebo Classic balances speed, graphics, and computation power, making it a practical choice for many use cases.</p>

            <h4>Features of Gazebo Classic:</h4>
            <ul>
                <li><strong>Ease of Sensor Integration:</strong><br>Gazebo plugins for both exteroceptive and proprioceptive sensors can be directly added to the robot description. Once configured, the robot can be spawned in a launch file with minimal setup.</li>
                <li><strong>Customizable Environments:</strong><br>Gazebo Classic allows custom environments to be designed with ease. Built-in primitives like walls, doors, and other elements can be directly picked and placed within the simulation interface. This feature enables users to create detailed environments even before generating a map.</li>
            </ul>

            <h4>Example: Custom Robot in a Custom Environment</h4>
            <p>Take a look at the <strong>custom robot in a custom Gazebo Classic environment</strong>.</p>
            <div style="text-align: center;">
                <img src="https://raw.githubusercontent.com/MYBOTSHOP/media/refs/heads/main/thesis/dw/nl/gazebo_env.webp" alt="Gazebo classic environment with custom robot">
            </div>
            <p>In this example, the robot operates within a slightly modified environment, featuring walls surrounding the right side of the compound. Such modifications are effortless thanks to the built-in graphical interface.</p>

            <h4>Advantages of Gazebo Classic:</h4>
            <ul>
                <li><strong>Speed:</strong><br>Gazebo Classic is faster than Isaac Sim because it does not require high-definition simulations. While it is slightly slower than Gazebo Fortress during initial loading, it operates seamlessly once loaded.</li>
                <li><strong>User-Friendly Interface:</strong><br>Gazebo Classic’s built-in graphical interface simplifies the process of designing and testing environments for both indoor and outdoor scenarios.</li>
                <li><strong>Community Support:</strong><br>As a legacy platform, Gazebo Classic boasts extensive online support and documentation, unlike the relatively newer Gazebo Fortress.</li>
            </ul>

            <h4>A Drawback: Lack of Realistic Crowd Animation</h4>
            <p>While Isaac Sim offers realistic crowd animation to test moving humans in a simulated environment, Gazebo Classic does not have this feature. However, Gazebo Classic compensates for this limitation by allowing objects to be dropped in the middle of navigation to test <strong>dynamic obstacle detection</strong>. This functionality ensures that algorithms can still be validated for real-world scenarios involving unexpected obstacles.</p>

            <h4>Use Cases for Gazebo Classic:</h4>
            <p>Gazebo Classic is an excellent choice for testing algorithms, designing robots, and simulating indoor and outdoor environments. Its combination of moderate computational requirements, reasonable graphics, and faster performance makes it a practical option for those who prioritize functionality over high-definition realism.</p>

            
            <h2>Gazebo Fortress: The Bridge Between Classic and Modern Simulation</h2>
            <p>Gazebo Fortress, the successor to Gazebo Classic, brings modern features and improved performance while maintaining the familiar usability of its predecessor. It offers enhanced simulation capabilities, making it a strong contender for robotics testing. However, it also introduces some complexities compared to Gazebo Classic, especially for those migrating existing ROS2 packages.</p>

            <h4>Key Features of Gazebo Fortress:</h4>
            <ul>
                <li><strong>Improved Graphics and High-Definition Simulation:</strong><br>Gazebo Fortress enhances the graphical fidelity over Classic, offering more immersive environments. While not as graphically detailed as Isaac Sim, Fortress strikes a balance between realism and performance.</li>
                <li><strong>Better Support for Dynamic Environments:</strong><br>Fortress introduces features like improved collision detection and smoother handling of dynamic objects, which are critical for testing algorithms involving moving obstacles.</li>
                <li><strong>Enhanced Plugin Ecosystem:</strong><br>A rich plugin ecosystem allows for better integration of sensors and actuators, providing more flexibility for robot developers.</li>
                <li><strong>Support for ROS 2 Packages:</strong><br>Migrating ROS 2 packages from Gazebo Classic to Fortress is relatively straightforward, thanks to the <a href="https://gazebosim.org/docs/fortress/migrating_gazebo_classic_ros2_packages/">migration guide</a>. However, some adaptation may be needed, especially for custom robots or environments.</li>
            </ul>

            <h4>Example: A Custom Four-Wheel Robot in Gazebo Fortress</h4>
            <p>Take a look at the <strong>GIF below</strong>, showcasing <strong>a custom four-wheel robot designed in Gazebo Fortress</strong>. The robot demonstrates how Fortress’s enhanced features allow for more detailed and accurate simulations of navigation and other robotic functions.</p>
            <div style="text-align: center;">
                <img src="https://raw.githubusercontent.com/MYBOTSHOP/media/refs/heads/main/thesis/dw/nl/fortress_robot.webp" alt="Gazebo Fortress Custom Robot Design">
            </div>

            <h4>Observations on Gazebo Fortress Environment</h4>
            <p>The <strong>Gazebo Fortress environment</strong> supports advanced features such as better collision detection and handling of dynamic obstacles. This makes it a suitable choice for testing algorithms in environments requiring higher fidelity than Gazebo Classic while maintaining a manageable computational load compared to Isaac Sim.</p>

            <h4>Observations and Trade-Offs:</h4>
            <ul>
                <li><strong>Performance vs. Graphics:</strong><br>While Gazebo Fortress improves graphical fidelity, it requires more processing power than Classic, though significantly less than Isaac Sim. This makes it a middle ground between the two platforms.</li>
                <li><strong>Dynamic Obstacle Handling:</strong><br>Fortress performs better than Classic in handling dynamic objects, making it suitable for navigation scenarios involving moving humans or obstacles. However, Isaac Sim still leads in dynamic crowd animation.</li>
                <li><strong>Learning Curve:</strong><br>For those already familiar with Gazebo Classic, transitioning to Fortress is manageable with the help of the <a href="https://gazebosim.org/docs/fortress/migrating_gazebo_classic_ros2_packages/">migration guide</a>. On the other hand, Isaac Sim’s steep learning curve might pose a challenge for newcomers.</li>
            </ul>

            <h4>Recommendation:</h4>
            <p>Gazebo Fortress is ideal for those seeking a balance between performance, graphics, and usability. It is particularly well-suited for developers migrating from Gazebo Classic or those looking for advanced features without the heavy computational requirements of Isaac Sim.</p>
        
        
        
            
            <h2>Incorporating Safety Protocols into Digital Twin Environments</h2>
            <p>To ensure robust and safe human-robot interactions (HRI) in dynamic retail environments, several safety protocols have been identified and integrated into digital twin simulations. These protocols are designed to address potential hazards, ensure compliance with regulatory standards, and improve the reliability of robots operating in close proximity to humans.</p>

            <h3>ISO 13482 – The New Safety Standard for Personal Care Robots</h3>
            <p><strong>Introduction</strong><br>
            ISO 13482 is a groundbreaking safety standard tailored for personal care robots operating in close interaction with humans in non-industrial settings. These robots assist humans in tasks such as mobility and support, where safe physical interaction is critical. By emphasizing collision avoidance, force limits, and autonomous decision-making safety mechanisms, ISO 13482 establishes a comprehensive framework for ensuring safety.</p>

            <p>As my work focuses on developing digital twin-driven safety protocols for human-robot interaction (HRI) in retail environments using NVIDIA Isaac Sim, incorporating ISO 13482 ensures virtual and real-world robots adhere to internationally recognized safety standards.</p>

            <h4>The Need for Incorporating ISO 13482 in Retail Robotics</h4>
            <ul>
                <li><strong>Close Proximity Operations:</strong> Robots often share spaces with people, requiring protocols to mitigate risks such as collisions or incorrect autonomous decisions.</li>
                <li><strong>Human-Centric Risk Mitigation:</strong> The standard offers structured approaches to reducing hazards like physical contact, object mismanagement, and navigation errors.</li>
                <li><strong>Compliance with Legal Standards:</strong> Adherence to ISO 13482 ensures that robots meet safety regulations essential for commercial deployment in retail settings.</li>
            </ul>

            <h4>Application in a Digital Twin Simulation Environment</h4>
            <ul>
                <li><strong>Simulating Hazard Scenarios:</strong> Guidelines for identifying hazards like collisions or loss of stability can be simulated to refine safety protocols.</li>
                <li><strong>Testing Safety Measures Virtually:</strong> Force and speed limits, collision avoidance, and emergency stops can be validated before physical deployment.</li>
                <li><strong>Validating Autonomous Decisions:</strong> Robots' decision-making algorithms are tested for robustness, ensuring safe navigation in complex retail scenarios.</li>
            </ul>

            <h3>IEEE P7009 – Fail-Safe Design Standard for Autonomous Systems</h3>
            <p><strong>Introduction</strong><br>
            The IEEE P7009 standard provides a framework for developing fail-safe mechanisms in autonomous and semi-autonomous systems. It focuses on transitioning systems to safe states during failures, ensuring safety without requiring human intervention. By incorporating fail-safe designs that autonomously detect and respond to failures, the standard minimizes potential harm and ensures predictable system behavior.</p>

            <p>In this work, IEEE P7009 is integrated into a digital twin-driven approach using NVIDIA Isaac Sim to pre-validate fail-safe mechanisms for human-robot interaction (HRI) in retail environments. This allows for structured, risk-free testing of safety protocols in dynamic retail scenarios.</p>

            <h4>Application in a Digital Twin Simulation Environment</h4>
            <ul>
                <li><strong>Simulating Failure Scenarios:</strong> Simulate events such as sensor malfunctions, navigation errors, or sudden obstacles to assess the robot's response according to IEEE P7009.</li>
                <li><strong>Testing Autonomous Fail-Safe Responses:</strong> Evaluate responses like emergency stops, rerouting, or moving to safe zones in simulated environments.</li>
                <li><strong>Assessing Safety Protocol Effectiveness:</strong> Refine fail-safe protocols by measuring their effectiveness in simulation before physical deployment.</li>
            </ul>

            <h3>Safety Protocols, Their Relevance, and Future Work/Gaps</h2>
            <table>
                <thead>
                    <tr>
                        <th>Protocol Name</th>
                        <th>Summary</th>
                        <th>Relevance</th>
                        <th>Future Work/Gaps</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>ISO 13482</strong></td>
                        <td>Safety standard for personal care robots, ensuring safe physical interaction between robots and humans, focusing on risk reduction and hazard management.</td>
                        <td>Ensures safe human-robot interaction in retail by providing guidelines on collision avoidance, force limits, and risk mitigation.</td>
                        <td>Has not been extensively tested in digital twin environments; future work could involve virtual validation before physical deployment.</td>
                    </tr>
                    <tr>
                        <td><strong>IEEE P7009</strong></td>
                        <td>Provides a framework for developing fail-safe mechanisms in autonomous systems, ensuring systems transition to safe states in case of failures.</td>
                        <td>Ensures robots in retail environments can prevent harm by transitioning to safe states during failures, aligning with fail-safe human-robot interaction protocols.</td>
                        <td>Future work should focus on integrating fail-safe mechanisms with digital twin simulations for better pre-validation of safety protocols in dynamic retail environments.</td>
                    </tr>
                    <tr>
                        <td><strong>IEEE 7001-2021</strong></td>
                        <td>Provides measurable, testable levels of transparency for autonomous systems, ensuring that their decision-making processes are discoverable and understandable.</td>
                        <td>Ensures that retail robots interacting with humans operate transparently, making it possible to understand why and how the system made specific decisions.</td>
                        <td>Ethical work should explore integrating transparency measures into digital twin simulations to validate the robot’s behavior before real-world deployment.</td>
                    </tr>
                    <tr>
                        <td><strong>IEEE 1228</strong></td>
                        <td>Provides guidelines for developing safety plans for software systems, addressing potential software failures in safety-critical applications.</td>
                        <td>Relevant for designing safety plans for robot control software, ensuring software failures are anticipated and mitigated in human-robot interaction scenarios.</td>
                        <td>Needs greater attention to unplanned software updates and their impact on safety in retail.</td>
                    </tr>
                    <tr>
                        <td><strong>ISO/TS 15066</strong></td>
                        <td>Safety standards for collaborative robots (cobots), focusing on limits for force and speed to ensure safe human-robot interaction.</td>
                        <td>Guides safety protocols for collaborative robots in retail, where safe interactions with force and speed limits are required.</td>
                        <td>Future work involves refining force thresholds based on real-world interaction feedback in retail scenarios.</td>
                    </tr>
                    <tr>
                        <td><strong>ISO 12100</strong></td>
                        <td>Defines principles for risk assessment and reduction in machinery, providing guidelines to identify hazards and implement protective measures.</td>
                        <td>Provides a framework for risk assessment and mitigation in digital twin simulations, assisting in the development of safety protocols for retail robot behavior.</td>
                        <td>Need to validate assessment models through iterative tests in digital twin and real-world conditions.</td>
                    </tr>
                </tbody>
            </table>



            <h2>Data Protection Policies: Ensuring Privacy in Retail Robot Operations</h2>
            <p>After discussing and identifying some of the key safety protocols—an integral part of any retail store environment—we now focus on <strong>data protection policies</strong>. Privacy is a critical concern, as most people would want their personal information, including facial data, to remain secure. At the same time, detection using cameras is an essential aspect of ensuring the safety and protection of people around robots.</p>
            <p>To address this challenge, a solution must allow robots to detect individuals in a retail store environment <strong>without compromising their privacy</strong>. For example, a robot could detect a person’s presence, blur their face region, and display this blurred face on the robot's interface. This ensures the person's identity is protected while the robot continues to navigate safely, avoiding possible collisions.</p>

            <table>
                <thead>
                    <tr>
                        <th>Protocol Name</th>
                        <th>Summary</th>
                        <th>Relevance</th>
                        <th>Future Work/Gaps</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>IEEE 7000</strong></td>
                        <td>Ethical guidelines for system design, focusing on privacy, transparency, and data protection in systems interacting with humans.</td>
                        <td>Guides ethical implementation of robotics, ensuring privacy, transparency, and data management where robots interact with people, especially in retail.</td>
                        <td>Ethical principles need wider adoption in robotic design, especially in automated decision-making and transparency in human-robot interactions.</td>
                    </tr>
                    <tr>
                        <td><strong>GDPR</strong></td>
                        <td>Regulates data protection and privacy in the EU, providing guidelines for lawful data processing, ensuring consent, transparency, and the right to erasure.</td>
                        <td>Ensures personal data collected during person detection in retail is handled securely and compliant with privacy regulations.</td>
                        <td>Further refinement is needed in automated anonymization, real-time monitoring, and adapting to evolving privacy and security requirements.</td>
                    </tr>
                </tbody>
            </table>

            <h3>Leveraging Ultralytics YOLO11 for Privacy Protection</h3>
            <p>During the exploration of data protection policies, I utilized the latest release from Ultralytics: <strong>YOLOv11</strong>. Compared to YOLOv8, YOLOv11 is significantly faster and more accurate, making it an excellent choice for implementing privacy features like object blurring.</p>

            <h4>Benefits of Using YOLOv11 for Object Blurring:</h4>
            <ul>
                <li><strong>Privacy Protection:</strong> Effectively obscures sensitive or identifiable information, ensuring compliance with data protection policies like GDPR.</li>
                <li><strong>Selective Focus:</strong> Targets specific objects (e.g., faces) for blurring, while maintaining essential visual content for navigation and safety.</li>
                <li><strong>Real-Time Processing:</strong> Executes object blurring efficiently in dynamic environments, making it suitable for instant privacy enhancements.</li>
            </ul>
            <p>Using YOLOv11, I trained and deployed a model on the <strong>Go2 robot</strong>. As shown in the <strong>GIF below</strong>, the robot can detect a person’s face, blur the region effectively, and display this blurred view on its screen. This functionality works as long as the person remains within the robot camera’s frame.</p>
            <img src="https://raw.githubusercontent.com/MYBOTSHOP/media/refs/heads/main/thesis/dw/nl/faceblur_1.webp" alt="Object Blurring GIF">

            <h3>YOLOv11 Performance Comparison</h3>
            <p>The chart below illustrates how YOLOv11 outperforms earlier models like YOLOv8 in terms of speed and accuracy. YOLOv11 introduces significant improvements, making it the preferred choice for real-time applications such as privacy-focused object detection and blurring.</p>
            <img src="https://raw.githubusercontent.com/ultralytics/assets/refs/heads/main/yolo/performance-comparison.png" alt="YOLOv11 Performance Comparison">
            <p style="text-align: center;">
                <em><a href="https://raw.githubusercontent.com/ultralytics/assets/refs/heads/main/yolo/performance-comparison.png">Comparision of ultralytics yolo models</a></em>
            </p>

            <h4>Key Observations:</h4>
            <ul>
                <li><strong>Speed:</strong> YOLOv11 processes frames faster than YOLOv8, making it ideal for dynamic environments like retail stores where robots must respond quickly.</li>
                <li><strong>Accuracy:</strong> YOLOv11 demonstrates higher detection accuracy compared to YOLOv8, ensuring reliable identification and processing of objects and faces.</li>
                <li><strong>Efficiency in Privacy Tasks:</strong> With improved performance metrics, YOLOv11 ensures privacy protection features, such as object blurring, are executed without compromising system speed or functionality.</li>
            </ul>

            <h3>Generalization Across Cameras</h3>
            <p>An important note: while this application was tested with the Go2 robot, it is designed to work with other cameras as well, including the <strong>ZED 2i</strong>. This flexibility ensures the solution can be applied across different hardware configurations, enhancing its usability in diverse environments.</p>
            <p>For more details about YOLOv11, refer to the <a href="https://docs.ultralytics.com/models/yolo11/">Ultralytics YOLO11 Documentation</a>.</p>

            <h3>Exploring Object Detection with ZED 2i Camera</h3>
            <p>Before discussing use cases using Navigation2 in ROS2 Humble, I wanted to explore validation in a simulation environment by tackling a hands-on task. To do this, I worked with the industrial-level depth camera <strong>ZED 2i</strong> (refer to the image below).</p>
            <p>Depth cameras are a crucial component of any robot. Acting as the robot's eyes, they enable the robot to not only see objects but also infer their distance from the camera. Unlike standard fisheye cameras, depth cameras like the ZED 2i allow robots to estimate the 3D pose of objects relative to the camera, which is vital for tasks such as navigation and object interaction.</p>

            <h4>Why Depth Cameras Matter</h4>
            <ul>
                <li><strong>Object Localization:</strong> Depth cameras help estimate the location of objects in the environment while the robot is moving.</li>
                <li><strong>Human-Robot Interaction:</strong> They enable robots to classify objects and humans, improving situational awareness in dynamic environments like retail stores.</li>
                <li><strong>Pose Estimation:</strong> The 3D pose of objects can be calculated, helping robots identify the orientation and position of objects.</li>
            </ul>
            <p>As shown in the <strong>GIF below</strong>, the robot classified a handbag with approximately 84% accuracy, demonstrating the capability to detect and classify objects. This was achieved using a trained YOLOv8 model, with data preprocessing and augmentation performed using <strong>RoboFlow</strong>.</p>
            <img src="https://raw.githubusercontent.com/MYBOTSHOP/media/refs/heads/main/thesis/dw/nl/Object_detection_wrt_camera_frame.webp" alt="3D Object Pose Detection">

            <h3>Why I Chose YOLOv8</h3>
            <p>I selected the YOLOv8 model for this task because of its flexibility and support for multiple tasks such as detection, classification, and segmentation. Below is a comparison of its key features, which influenced my decision:</p>
            <table>
                <thead>
                    <tr>
                        <th>Feature</th>
                        <th>YOLOv8</th>
                        <th>YOLOv5</th>
                        <th>YOLOv4</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>Architecture</strong></td>
                        <td>Unified Detection, Segmentation, Classification</td>
                        <td>Separate models</td>
                        <td>Separate models</td>
                    </tr>
                    <tr>
                        <td><strong>Speed</strong></td>
                        <td>Faster than YOLOv5</td>
                        <td>Moderate</td>
                        <td>Slower</td>
                    </tr>
                    <tr>
                        <td><strong>Accuracy</strong></td>
                        <td>Improved</td>
                        <td>High</td>
                        <td>Moderate</td>
                    </tr>
                    <tr>
                        <td><strong>Supported Modes</strong></td>
                        <td>Detection, Classification, Segmentation</td>
                        <td>Detection, Classification</td>
                        <td>Detection only</td>
                    </tr>
                    <tr>
                        <td><strong>Ease of Use</strong></td>
                        <td>Intuitive</td>
                        <td>Intuitive</td>
                        <td>Moderate</td>
                    </tr>
                </tbody>
            </table>

            <p>
                For more details, refer to the <a href="https://docs.ultralytics.com/models/yolov8/">YOLOv8 documentation</a>.
            </p>
            <p>Additionally, the comparison image below illustrates YOLOv8’s performance metrics relative to previous versions, highlighting its superior speed and accuracy.</p>
            <img src="https://github.com/ultralytics/docs/releases/download/0/yolov8-comparison-plots.avif" alt="YOLOv8 Comparison">
            <p style="text-align: center;">
                <em><a href="https://docs.ultralytics.com/models/yolov8/">YOLOv8 comparision with earlier yolo models</a></em>
            </p>

            <h3>Why I Chose ZED 2i</h3>
            <p>The <strong>ZED 2i</strong> camera was an ideal choice for this task due to its built-in <strong>body tracking feature</strong>. In dynamic environments like retail stores, where humans are continuously moving, it is critical to track human bodies effectively. The ZED 2i’s advanced capabilities, such as tracking 18 key points of the human body, enable precise and reliable tracking.</p>
            <p><em>Refer to the <a href="https://www.stereolabs.com/docs/body-tracking/">ZED 2i Body Tracking Documentation</a> for more details.</em></p>
            <p>Here’s a visual representation of the 18 key points tracked by the ZED 2i camera:</p>
            <div style="text-align: center;">
                <img src="https://docs.stereolabs.com/body-tracking/images/keypoints_body18.png" alt="Body Tracking Key Points">
            </div>
            <p>Below is a <strong>GIF of a scene showcasing keypoints being detected in real-time</strong> using the ZED 2i camera:</p>
            <img src="https://raw.githubusercontent.com/MYBOTSHOP/media/refs/heads/main/thesis/dw/nl/bodytracking.webp" alt="Keypoints Detection GIF">
            <p>The GIF illustrates how the ZED 2i camera accurately tracks and detects human movements by identifying body keypoints, ensuring seamless performance in dynamic environments like retail stores.</p>
            <p>Another compelling reason for experimenting with the ZED 2i camera is its <strong>availability within Isaac Sim</strong>. NVIDIA Isaac Sim supports the ZED 2i camera as a virtual sensor, allowing developers to test and validate robotics applications in high-fidelity simulated environments before deploying them in real-world scenarios.</p>
            
            <div style="text-align: center;">
                <img src="https://docs.stereolabs.com/isaac-sim/images/ZED_in_isaac_sim.jpg" alt="zed2i in isaac sim">
            </div>
            <p style="text-align: center;"><em><a href="https://www.stereolabs.com/docs/isaac-sim">ZED2i Documentation for ROS2</a></em></p>




            <h3>Outcome and Applications</h3>
            <p>The combination of the ZED 2i camera and YOLOv8 allowed the robot to:</p>
            <ul>
                <li><strong>Classify Objects with High Accuracy:</strong> For example, identifying handbags, as shown in the GIF.
                <li><strong>Human Movements:</strong> The built-in body tracking feature ensured accurate tracking of humans, which is crucial in environments like retail stores.  
                <li><strong>Augmented Data:</strong></li>  Using RoboFlow for data preprocessing and augmentation streamlined the training process and improved detection accuracy.
                    
            </ul>    
                These insights and tools lay a strong foundation for creating robust object detection systems, especially in settings where robots need to navigate and interact with complex environments efficiently.</li>



            <h2>Understanding Robot Decision-Making: Local and Global Planners</h1>
            <p>Now that we have discussed the need to validate safety protocols and data protection policies—and identified each—it is time to explore what makes a robot autonomous. Specifically, we will dive into <strong>how robots make decisions in different scenarios</strong> and how planners influence these decisions during operation.</p>

            <h3>Local and Global Planners</h3>
            <p>Robots rely on two types of planners to navigate their environments: <strong>local planners</strong> and <strong>global planners</strong>. Each plays a distinct role in ensuring safe, efficient, and autonomous operation.</p>

            <table>
                <thead>
                    <tr>
                        <th>Aspect</th>
                        <th>Local Planner</th>
                        <th>Global Planner</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>Scope</td>
                        <td>Handles short-term, real-time navigation and obstacle avoidance.</td>
                        <td>Plans long-term paths from the robot’s start point to its goal.</td>
                    </tr>
                    <tr>
                        <td>Focus</td>
                        <td>Dynamic obstacle handling and maintaining a smooth, collision-free trajectory.</td>
                        <td>Optimizing the overall route based on the map, environment, and defined goals.</td>
                    </tr>
                    <tr>
                        <td>Frequency</td>
                        <td>Operates at a higher frequency (e.g., 10 Hz) for real-time adjustments.</td>
                        <td>Operates at a lower frequency (e.g., 1 Hz) to minimize computational overhead.</td>
                    </tr>
                    <tr>
                        <td>Impact on Safety</td>
                        <td>Ensures immediate responsiveness to nearby obstacles and path deviations.</td>
                        <td>Avoids hazardous routes or areas that could compromise the robot's operation.</td>
                    </tr>
                    <tr>
                        <td>Key Parameters</td>
                        <td>Velocity limits, inflation radius, yaw tolerance for precise control.</td>
                        <td>Map cost layers, goal tolerance for efficient and safe long-term planning.</td>
                    </tr>
                </tbody>
            </table>

            <h3>Nav2 Global Planners and Local Controllers</h3>
            <p>The Nav2 stack provides a robust framework for implementing local and global planners, each tailored to specific use cases and operational environments. The table below categorizes the available planners and controllers:</p>

            <table>
                <thead>
                    <tr>
                        <th>Type</th>
                        <th>Name</th>
                        <th>Description</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>Global Planner</td>
                        <td>NavFn Planner</td>
                        <td>Utilizes Dijkstra's algorithm to compute the shortest path on a costmap.</td>
                    </tr>
                    <tr>
                        <td>Global Planner</td>
                        <td>Smac Planner</td>
                        <td>Offers different variants, including 2D and Hybrid-A* planners, suitable for various robot types and environments.</td>
                    </tr>
                    <tr>
                        <td>Global Planner</td>
                        <td>Theta Planner</td>
                        <td>Computes paths that are more direct by allowing diagonal movements, reducing unnecessary turns.</td>
                    </tr>
                    <tr>
                        <td>Local Controller</td>
                        <td>DWB (Dynamic Window Approach)</td>
                        <td>Evaluates a set of possible trajectories and selects the one that optimally balances progress toward the goal, speed, and obstacle avoidance.</td>
                    </tr>
                    <tr>
                        <td>Local Controller</td>
                        <td>Regulated Pure Pursuit</td>
                        <td>Focuses on following the global path accurately, adjusting the robot's speed based on proximity to obstacles and path curvature.</td>
                    </tr>
                    <tr>
                        <td>Local Controller</td>
                        <td>MPPI (Model Predictive Path Integral)</td>
                        <td>Uses a model predictive control approach to optimize control commands over a future horizon, considering the robot's dynamics and environmental constraints.</td>
                    </tr>
                    <tr>
                        <td>Local Controller</td>
                        <td>Rotation Shim Controller</td>
                        <td>Handles in-place rotation behaviors, ensuring the robot can correctly orient itself before proceeding along the path.</td>
                    </tr>
                </tbody>
            </table>

            <h3>Moving Forward</h3>
            <p>In the following sections, we will explore how these planners influence robot behavior in specific scenarios:</p>
            <ol>
                <li>Going in a Straight Line</li>
                <li>Navigating Around Static Obstacles</li>
                <li>Navigating Around Dynamic Obstacles</li>
            </ol>

            <h3>Relevant Parameters for Navigation Experiments</h3>
            <p>These are the default parameters of the Nav2 stack. In the following experiments, these parameters will be tweaked for different scenarios, planners, and controllers:</p>

            <table>
                <thead>
                    <tr>
                        <th>Parameter Group</th>
                        <th>Parameter Name</th>
                        <th>Value</th>
                        <th>Purpose/Description</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>AMCL Configuration</td>
                        <td>use_sim_time</td>
                        <td>True</td>
                        <td>Ensures simulation time is used for synchronization.</td>
                    </tr>
                    <tr>
                        <td>Controller Server</td>
                        <td>controller_frequency</td>
                        <td>20.0</td>
                        <td>Frequency at which local controllers compute control commands.</td>
                    </tr>
                    <tr>
                        <td>Costmap Parameters</td>
                        <td>local_costmap.width</td>
                        <td>3.0</td>
                        <td>Defines the width of the local costmap in meters.</td>
                    </tr>
                    <!-- Add more rows as needed -->
                </tbody>
            </table>



            <h4>Combination 1: NavFn Planner + DWB Local Planner</h4>
            <p>This configuration employs the <strong>NavFn Planner</strong> for global path planning and the <strong>DWB Local Planner</strong> for local trajectory adjustments.</p>

            <table>
                <thead>
                    <tr>
                        <th>Component</th>
                        <th>Plugin/Server</th>
                        <th>Type</th>
                        <th>Description</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>Planner Server</td>
                        <td><code>nav2_navfn_planner/NavfnPlanner</code></td>
                        <td>Global Planner</td>
                        <td>Computes the shortest path from start to goal using Dijkstra's algorithm on a costmap.</td>
                    </tr>
                    <tr>
                        <td>Controller Server</td>
                        <td><code>dwb_core::DWBLocalPlanner</code></td>
                        <td>Local Controller</td>
                        <td>Evaluates possible trajectories and selects the one that optimally balances progress, speed, and obstacle avoidance.</td>
                    </tr>
                </tbody>
            </table>

            <h5>Observations and Results</h5>
            <ol>
                <li>
                    <strong>Straight-Line Movement</strong><br>
                    <ul>
                        <li>The robot adhered closely to the planned trajectory with minimal drift.</li>
                        <li>Smooth motion was achieved by tuning parameters such as <code>max_velocity</code> and <code>yaw_goal_tolerance</code>.</li>
                    </ul>
                    <div style="text-align: center;">
                        <img src="https://raw.githubusercontent.com/MYBOTSHOP/media/refs/heads/main/thesis/dw/comb_1/straightline.webp" alt="Straight-Line Movement GIF" style="width:100%; max-width:600px;">

                    </div>
                    <div class="note">
                        <strong>Note:</strong> The scene is speed-forwarded and does not reflect true speed (i.e., 0.26 m/s).
                    </div>
                </li>
                <li>
                    <strong>Static Obstacles</strong><br>
                    <ul>
                        <li>The robot slowed down at the junction and adjusted its speed.</li>
                        <li>Trajectory adjustments were made by the robot, and it remained on the global path.</li>
                        <li>Minor path deviations were corrected by the local controller.</li>
                    </ul>
                    <div style="text-align: center;">
                        <img src="https://raw.githubusercontent.com/MYBOTSHOP/media/refs/heads/main/thesis/dw/comb_1/aroundstatic.webp" alt="Static Obstacles GIF" style="width:100%; max-width:600px;">

                    </div>
                </li>
                <li>
                    <strong>Dynamic Obstacles</strong><br>
                    <ul>
                        <li>The robot successfully responded to a moving cube as a placeholder for a moving person but exhibited slight delays when encountering faster objects.</li>
                        <li>The robot did not collide with the moving cube.</li>
                        <li>The robot did not maintain a safe distance, likely due to suboptimal tuning of parameters such as <code>inflation_radius</code>, <code>PathDist.scale</code>, or <code>obstacle_max_range</code> in the local and global costmaps.</li>
                    </ul>
                    <div style="text-align: center;">
                        <img src="https://raw.githubusercontent.com/MYBOTSHOP/media/refs/heads/main/thesis/dw/comb_1/DynamicObstacles.webp" alt="Dynamic Obstacles GIF" style="width:100%; max-width:600px;">
                    </div>
                </li>
            </ol>

            <h5>Performance Summary</h5>
            <table>
                <thead>
                    <tr>
                        <th>Scenario</th>
                        <th>Performance</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>Straight-Line Movement</td>
                        <td>Smooth and precise navigation.</td>
                    </tr>
                    <tr>
                        <td>Static Obstacles</td>
                        <td>Reliable obstacle avoidance with minor deviations.</td>
                    </tr>
                    <tr>
                        <td>Dynamic Obstacles</td>
                        <td>Adequate responsiveness to slow-moving obstacles; improvement needed for fast-moving objects and maintaining safe distance.</td>
                    </tr>
                </tbody>
            </table>

            <h5>Future Considerations</h5>
            <ul>
                <li>The <strong>TEB Local Planner</strong> could be explored for enhanced handling of dynamic obstacles.</li>
                <li>The <strong>Theta* Global Planner</strong> may be utilized for more direct and efficient path generation.</li>
            </ul>



            <h4>Combination 2: NavFn Planner + MPPI Controller</h4>
            <p>This configuration utilizes the <strong>NavFn Planner</strong> for global path planning and the <strong>MPPI (Model Predictive Path Integral) Controller</strong> for local trajectory optimization. This combination is designed to balance efficiency, smoothness, and dynamic obstacle handling.</p>

            <h5>Why MPPI Controller is a Good Choice</h5>
            <p>The <strong>MPPI Controller</strong> is well-suited for dynamic environments requiring real-time adjustments. It optimizes trajectories by considering the robot’s dynamics and environmental constraints, making it highly effective for:</p>
            <ul>
                <li><strong>Dynamic Obstacle Avoidance:</strong> Evaluates multiple trajectories to select the optimal path while avoiding collisions.</li>
                <li><strong>Smooth Path Generation:</strong> Produces jerk-free motions for stable operations.</li>
                <li><strong>Real-Time Performance:</strong> Delivers responsive and efficient control in dynamic scenarios.</li>
            </ul>

            <h5>Relevant Parameters for MPPI Controller</h5>
            <table>
                <thead>
                    <tr>
                        <th>Parameter</th>
                        <th>Value</th>
                        <th>Description</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><code>time_horizon</code></td>
                        <td>1.5</td>
                        <td>Time horizon over which the trajectory is optimized.</td>
                    </tr>
                    <tr>
                        <td><code>desired_linear_velocity</code></td>
                        <td>0.5</td>
                        <td>Target velocity for the robot's linear motion.</td>
                    </tr>
                    <tr>
                        <td><code>desired_angular_velocity</code></td>
                        <td>1.0</td>
                        <td>Target velocity for the robot's angular motion.</td>
                    </tr>
                    <tr>
                        <td><code>linear_acceleration_limit</code></td>
                        <td>2.0</td>
                        <td>Maximum allowed linear acceleration for smoother motion.</td>
                    </tr>
                    <tr>
                        <td><code>angular_acceleration_limit</code></td>
                        <td>3.0</td>
                        <td>Maximum allowed angular acceleration for smoother turns.</td>
                    </tr>
                    <tr>
                        <td><code>optimizer_iterations</code></td>
                        <td>1000</td>
                        <td>Number of iterations for trajectory optimization in each cycle.</td>
                    </tr>
                    <tr>
                        <td><code>cost_weights.path_following</code></td>
                        <td>10.0</td>
                        <td>Weight for staying close to the planned path.</td>
                    </tr>
                    <tr>
                        <td><code>cost_weights.collision_avoidance</code></td>
                        <td>15.0</td>
                        <td>Weight for avoiding collisions with obstacles.</td>
                    </tr>
                    <tr>
                        <td><code>cost_weights.smoothness</code></td>
                        <td>5.0</td>
                        <td>Weight for ensuring smooth trajectories.</td>
                    </tr>
                    <tr>
                        <td><code>lookahead_dist</code></td>
                        <td>0.6</td>
                        <td>Distance ahead of the robot for trajectory optimization.</td>
                    </tr>
                    <tr>
                        <td><code>transform_tolerance</code></td>
                        <td>0.1</td>
                        <td>Tolerance for transform lookups to ensure stability in real-time adjustments.</td>
                    </tr>
                    <tr>
                        <td><code>visualize_optimizer</code></td>
                        <td>true</td>
                        <td>Enables visualization of the optimized trajectories for debugging in RViz.</td>
                    </tr>
                </tbody>
            </table>

            <h5>Testing Scenarios and Observations</h5>
            <ol>
                <li>
                    <strong>Straight-Line Movement</strong><br>
                    <ul>
                        <li>The robot followed a smooth and precise trajectory with minimal drift.</li>
                        <li>Real-time trajectory optimization ensured stable motion.</li>
                    </ul>
                    <div style="text-align: center;">
                        <img src="https://raw.githubusercontent.com/MYBOTSHOP/media/refs/heads/main/thesis/dw/comb_2/straightline.webp" alt="Straight-Line Movement GIF" style="width:100%; max-width:600px;">
                    </div>
                </li>
                <li>
                    <strong>Navigating Static Obstacles</strong><br>
                    <ul>
                        <li>The controller successfully adjusted the robot's path to avoid obstacles, maintaining smooth transitions.</li>
                        <li>Dynamic trajectory optimization minimized unnecessary deviations.</li>
                    </ul>
                    <div style="text-align: center;">
                        <img src="https://raw.githubusercontent.com/MYBOTSHOP/media/refs/heads/main/thesis/dw/comb_2/static.webp" alt="Static Obstacles GIF" style="width:100%; max-width:600px;">
                    </div>
                </li>
                <li>
                    <strong>Navigating Dynamic Obstacles</strong><br>
                    <ul>
                        <li>The robot responded effectively to moving obstacles, recalculating the trajectory in real time.</li>
                        <li>The robot maintained a safe distance from the moving object.</li>
                        <li>Optimized control commands reduced delays in avoiding faster-moving objects.</li>
                    </ul>
                    <div style="text-align: center;">
                        <img src="https://raw.githubusercontent.com/MYBOTSHOP/media/refs/heads/main/thesis/dw/comb_2/dynamic.webp" alt="Dynamic Obstacles GIF" style="width:100%; max-width:600px;">
                    </div>
                </li>
            </ol>

            <h5>Performance Summary</h5>
            <table>
                <thead>
                    <tr>
                        <th>Scenario</th>
                        <th>Performance</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>Straight-Line Movement</td>
                        <td>Smooth and precise navigation.</td>
                    </tr>
                    <tr>
                        <td>Static Obstacles</td>
                        <td>Reliable obstacle avoidance with smooth trajectory adjustments.</td>
                    </tr>
                    <tr>
                        <td>Dynamic Obstacles</td>
                        <td>Effective real-time responses to moving obstacles.</td>
                    </tr>
                </tbody>
            </table>

            <h5>Conclusion</h5>
            <p>The combination of <strong>NavFn Planner</strong> and <strong>MPPI Controller</strong> provided robust performance across all scenarios. Its ability to handle dynamic obstacles and generate smooth trajectories makes it an excellent choice for complex environments.</p>

            <h6>Future Improvements</h6>
            <ul>
                <li>Further tuning of <strong>cost weights</strong> and <strong>time horizon</strong> could enhance responsiveness in highly dynamic settings.</li>
                <li>Exploring alternate global planners, such as <strong>Smac (Hybrid-A*)</strong>, may yield better path efficiency for intricate environments.</li>
            </ul>



            <h4>Combination 3: NavFn Planner + Regulated Pure Pursuit Controller</h4>
            <p>This configuration utilizes the <strong>NavFn Planner</strong> for global path planning and the <strong>Regulated Pure Pursuit Controller</strong> for local trajectory adjustments. While this combination is highly efficient for straight-line movements, its performance diminishes when navigating through close proximities or dynamic environments.</p>
        
            <h5>Why Regulated Pure Pursuit Controller is a Good Choice</h5>
            <p>The <strong>Regulated Pure Pursuit Controller</strong> is known for its simplicity and reliability in following global paths, particularly in open environments. It is designed to scale its velocity based on proximity to obstacles and path curvature, ensuring smooth and precise motion.</p>
            <ul>
                <li><strong>Ideal for Straight-Line Movements:</strong> Ensures smooth and predictable navigation without significant path deviations.</li>
                <li><strong>Velocity Regulation:</strong> Dynamically adjusts speed to maintain safety when approaching obstacles.</li>
                <li><strong>Ease of Tuning:</strong> Fewer parameters compared to more complex controllers, simplifying configuration.</li>
            </ul>
        
            <h5>Relevant Parameters for Regulated Pure Pursuit Controller</h5>
            <table>
                <thead>
                    <tr>
                        <th>Parameter</th>
                        <th>Value</th>
                        <th>Description</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><code>desired_linear_vel</code></td>
                        <td>0.5</td>
                        <td>Target velocity for the robot's linear motion.</td>
                    </tr>
                    <tr>
                        <td><code>lookahead_dist</code></td>
                        <td>0.6</td>
                        <td>Distance ahead of the robot for trajectory adjustments.</td>
                    </tr>
                    <tr>
                        <td><code>min_lookahead_dist</code></td>
                        <td>0.3</td>
                        <td>Minimum distance for trajectory adjustments.</td>
                    </tr>
                    <tr>
                        <td><code>max_lookahead_dist</code></td>
                        <td>0.9</td>
                        <td>Maximum distance for trajectory adjustments.</td>
                    </tr>
                    <tr>
                        <td><code>rotate_to_heading_angular_vel</code></td>
                        <td>1.8</td>
                        <td>Angular velocity for orienting toward the path heading.</td>
                    </tr>
                    <tr>
                        <td><code>use_velocity_scaled_lookahead_dist</code></td>
                        <td>false</td>
                        <td>Disables scaling of lookahead distance based on velocity.</td>
                    </tr>
                    <tr>
                        <td><code>use_collision_detection</code></td>
                        <td>true</td>
                        <td>Enables obstacle detection for safer navigation.</td>
                    </tr>
                    <tr>
                        <td><code>max_allowed_time_to_collision_up_to_carrot</code></td>
                        <td>1.0</td>
                        <td>Maximum allowed time to potential collisions along the path.</td>
                    </tr>
                    <tr>
                        <td><code>min_approach_linear_velocity</code></td>
                        <td>0.05</td>
                        <td>Minimum velocity when approaching a goal or obstacle.</td>
                    </tr>
                    <tr>
                        <td><code>transform_tolerance</code></td>
                        <td>0.1</td>
                        <td>Tolerance for transform lookups to ensure stability in real-time adjustments.</td>
                    </tr>
                </tbody>
            </table>
        
            <h5>Testing Scenarios and Observations</h5>
            <ol>
                <li>
                    <strong>Straight-Line Movement</strong><br>
                    <ul>
                        <li>The robot navigated smoothly and efficiently, adhering to the global path without significant deviations.</li>
                        <li>Velocity regulation ensured stable and precise motion.</li>
                    </ul>
                    <div style="text-align: center;">
                        <img src="https://raw.githubusercontent.com/MYBOTSHOP/media/refs/heads/main/thesis/dw/comb_3/straight.webp" alt="Straight-Line Movement GIF" style="width:100%; max-width:600px;">
                    </div>
                </li>
                <li>
                    <strong>Navigating Static Obstacles</strong><br>
                    <ul>
                        <li>Performance was suboptimal, particularly when passing through close gaps.</li>
                        <li>The robot struggled with efficiency compared to other combinations like NavFn + DWB and NavFn + MPPI.</li>
                    </ul>
                    <div style="text-align: center;">
                        <img src="https://raw.githubusercontent.com/MYBOTSHOP/media/refs/heads/main/thesis/dw/comb_3/static2.webp" alt="Static Obstacles GIF" style="width:100%; max-width:600px;">
                    </div>
                </li>
                <li>
                    <strong>Navigating Dynamic Obstacles</strong><br>
                    <ul>
                        <li>The robot managed to replan and avoid moving obstacles, but the response time was slower than other controllers.</li>
                        <li>While it successfully reached the goal pose, the delay in path adjustments indicated limited efficiency in dynamic scenarios.</li>
                    </ul>
                    <div style="text-align: center;">
                        <img src="https://raw.githubusercontent.com/MYBOTSHOP/media/refs/heads/main/thesis/dw/comb_3/Dynamic.webp" alt="Dynamic Obstacles GIF" style="width:100%; max-width:600px;">
                    </div>
                </li>
            </ol>
        
            <h5>Performance Summary</h5>
            <table>
                <thead>
                    <tr>
                        <th>Scenario</th>
                        <th>Performance</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>Straight-Line Movement</td>
                        <td>Smooth and precise navigation, ideal for open spaces.</td>
                    </tr>
                    <tr>
                        <td>Static Obstacles</td>
                        <td>Struggled with close proximities, less efficient compared to other combinations.</td>
                    </tr>
                    <tr>
                        <td>Dynamic Obstacles</td>
                        <td>Slow in replanning and path adjustments, though able to reach the goal.</td>
                    </tr>
                </tbody>
            </table>
        
            <h5>Conclusion</h5>
            <p>The combination of <strong>NavFn Planner</strong> and <strong>Regulated Pure Pursuit Controller</strong> is well-suited for open environments with minimal obstacles. However, its limitations become evident in more complex scenarios, such as navigating through tight spaces or reacting to dynamic obstacles.</p>
        
            <h6>Future Improvements</h6>
            <ul>
                <li>Consider using <strong>DWB</strong> or <strong>MPPI</strong> for environments with close proximities or high dynamic activity.</li>
                <li>Fine-tune parameters like <code>lookahead_dist</code> and enable <strong>velocity-scaled lookahead</strong> for more responsive adjustments.</li>
            </ul>
        
            <h5>Interconnected Nodes in Nav2 Stack</h5>
            <p>To better understand the communication between various components of the Nav2 stack, here’s the <strong>RQT Graph</strong> visualization of interconnected nodes. This includes key nodes like the <strong>local cost map</strong>, <strong>global cost map</strong>, <strong>controller server</strong>, <strong>planner server</strong>, and <strong>behavior server</strong>.</p>
            <div style="text-align: center;">
                <img src="https://raw.githubusercontent.com/MYBOTSHOP/media/refs/heads/main/thesis/dw/comb_3/rosgraph.webp" alt="RQT Graph Visualization" style="width:100%; max-width:600px;">

            </div>
        
            <div class="note">
                <strong>Note:</strong> The RQT graph illustrates how these components interact to ensure smooth and efficient navigation. Each node plays a critical role:
                <ul>
                    <li><strong>Planner Server:</strong> Computes the global path.</li>
                    <li><strong>Controller Server:</strong> Adjusts the local trajectory for real-time obstacle avoidance.</li>
                    <li><strong>Behavior Server:</strong> Manages higher-level behaviors like spinning, backing up, and driving on heading.</li>
                    <li><strong>Cost Maps:</strong> Provide the environmental representation for planning and obstacle avoidance.</li>
                </ul>
                This interconnected structure ensures seamless communication and dynamic adaptability during navigation.

            </div>

            <h4>Combination 4: Theta* + Regulated Pure Pursuit Controller</h4>

            <h5>How Theta* Differs from Navfn Planner</h5>
            <p>The <strong>Theta*</strong> planner generates any-angle paths with smoother, more direct line segments, while <strong>Navfn</strong> is constrained to grid-based paths, resulting in more angular and less efficient routes.</p>

            <h5>Theta* + RPP: Observations and Insights</h5>

            <h6>Straight-Line Movement</h6>
            <p>In a straightforward scenario, the robot moved along a straight line as expected when the path was unobstructed. This behavior highlights the efficiency of the Theta* planner in generating direct, any-angle paths, reducing unnecessary turns, and optimizing the travel distance.</p>
            <div style="text-align: center;">
                <img src="https://raw.githubusercontent.com/MYBOTSHOP/media/refs/heads/main/thesis/dw/comb_4/straight.webp" alt="Straight-Line Movement" style="width:100%; max-width:600px;">
            </div>

            <h6>Static Environment</h6>
            <p>When multiple waypoints were provided, the robot recalculated the path dynamically instead of strictly following the given waypoints. It took a shortcut, reaching the goal faster than if it had adhered to the exact waypoints.</p>
            <p><strong>Reason:</strong> The Theta* planner is designed to optimize for the shortest and most efficient path between the start and goal. Waypoints, unless enforced as strict constraints, are treated as optional guides. The recalculated shortcut reflects the planner’s inherent focus on path optimization and reduced traversal time.</p>
            <div style="text-align: center;">
                <img src="https://raw.githubusercontent.com/MYBOTSHOP/media/refs/heads/main/thesis/dw/comb_4/static.webp" alt="Static Environment Shortcut" style="width:100%; max-width:600px;">
            </div>

            <h6>Dynamic Environment</h6>
            <p>In a dynamic setup, a walking person primitive was introduced as a moving obstacle:</p>
            <ul>
                <li><strong>First Trial:</strong> The robot collided with the moving person, likely due to limitations in the <strong>RPP local planner</strong> as observed in conjunction with the Navfn planner, which did not react quickly enough to the dynamic change.</li>
                <li><strong>Second Trial:</strong> After the person moved aside, the robot successfully stopped, recalculated a shorter path, and reached the goal.</li>
            </ul>
            <div style="text-align: center;">
                <img src="https://raw.githubusercontent.com/MYBOTSHOP/media/refs/heads/main/thesis/dw/comb_4/dynamic.webp" alt="Dynamic Successful Trial 2" style="width:100%; max-width:600px;">
            </div>
            <p><strong>Reason:</strong> This outcome underscores the adaptability of Theta* + RPP (Reactive Path Planning). The planner dynamically recalculated the path based on real-time updates, showcasing its ability to handle dynamic obstacles effectively. The successful adjustment in the second trial highlights the importance of robust integration between the global and local planning layers.</p>

            <h5>Performance Summary</h5>
            <table>
                <thead>
                    <tr>
                        <th>Feature</th>
                        <th>Performance</th>
                        <th>Comments</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>Straight-Line Movement</td>
                        <td>Smooth and efficient direct paths.</td>
                        <td>Theta* generates optimal, any-angle paths, making it ideal for open and unconstrained environments.</td>
                    </tr>
                    <tr>
                        <td>Static Obstacles</td>
                        <td>Dynamically recalculates efficient paths.</td>
                        <td>Bypasses unnecessary waypoints to optimize travel time and distance in static environments.</td>
                    </tr>
                    <tr>
                        <td>Dynamic Obstacles</td>
                        <td>Relies on the local planner for handling dynamic changes effectively.</td>
                        <td>RPP’s responsiveness impacts success; improvements in local planner integration could enhance reliability.</td>
                    </tr>
                </tbody>
            </table>

            <p>These observations illustrate the strengths of Theta* + RPP in both static and dynamic scenarios. While the planner excels at optimizing paths, ensuring a robust local planner is critical for managing dynamic obstacles in real-world environments.</p>




            <h4>Combination 5: Smac Planner + MPPI</h4>

            <h5>Navigation Performance: Testing Smac Planner + MPPI Controller</h5>
            <p>The combination of the <strong>Smac Planner</strong> and <strong>MPPI Controller</strong> represents an advanced setup designed to handle complex navigation scenarios. While the Smac Planner excels at generating smooth, kinematic-aware paths, the MPPI Controller provides real-time trajectory optimization and dynamic obstacle handling.</p>
        
            <h5>Testing Scenarios and Observations</h5>
            <ol>
                <li>
                    <strong>Straight-Line Movement</strong><br>
                    <ul>
                        <li>The robot performed satisfactorily, following a smooth and direct path.</li>
                        <li>No significant deviations or delays were observed.</li>
                    </ul>
                    <div style="text-align: center;">
                        <img src="https://raw.githubusercontent.com/MYBOTSHOP/media/refs/heads/main/thesis/dw/comb_5/Straight.webp" alt="Straight-Line Movement GIF" style="width:100%; max-width:600px;">
                    </div>
                </li>
                <li>
                    <strong>Navigating Static Obstacles</strong><br>
                    <ul>
                        <li>The Smac Planner generated a longer path to avoid obstacles.</li>
                        <li>As the robot approached the goal, it took additional time to stabilize.</li>
                        <li>The robot struggled slightly when passing through narrow gaps between walls, experiencing delays due to repeated replanning.</li>
                    </ul>
                    <div style="text-align: center;">
                        <img src="https://raw.githubusercontent.com/MYBOTSHOP/media/refs/heads/main/thesis/dw/comb_5/Static.webp" alt="Static Obstacles GIF" style="width:100%; max-width:600px;">
                    </div>
                </li>
                <li>
                    <strong>Navigating Dynamic Obstacles</strong><br>
                    <ul>
                        <li>The robot detected a moving wheelchair but was less robust in avoiding it compared to the NavFn + MPPI combination.</li>
                        <li>Multiple replanning attempts were necessary to successfully navigate around the obstacle.</li>
                        <li>Despite these challenges, the robot ultimately reached the goal.</li>
                    </ul>
                    <div style="text-align: center;">
                        <img src="https://raw.githubusercontent.com/MYBOTSHOP/media/refs/heads/main/thesis/dw/comb_5/Dynamic.webp" alt="Dynamic Obstacles GIF" style="width:100%; max-width:600px;">
                    </div>
                </li>
            </ol>
        
            <h5>Performance Summary</h5>
            <table>
                <thead>
                    <tr>
                        <th>Scenario</th>
                        <th>Performance</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>Straight-Line Movement</td>
                        <td>Smooth and efficient navigation.</td>
                    </tr>
                    <tr>
                        <td>Static Obstacles</td>
                        <td>Planned longer paths; delays in narrow gaps and stabilizing near the goal.</td>
                    </tr>
                    <tr>
                        <td>Dynamic Obstacles</td>
                        <td>Detected moving objects but struggled with robustness; required multiple replans.</td>
                    </tr>
                </tbody>
            </table>
        
            <h5>Conclusion</h5>
            <p>The combination of <strong>Smac Planner</strong> and <strong>MPPI Controller</strong> demonstrates strong potential for complex environments, particularly in scenarios requiring kinematic awareness and smooth trajectory optimization. However, challenges remain:</p>
            <ul>
                <li><strong>Static Obstacles:</strong> Path planning and stabilization need improvement for close proximities.</li>
                <li><strong>Dynamic Obstacles:</strong> Responsiveness to fast-moving objects requires further tuning.</li>
            </ul>
        
            <h6>Future Improvements</h6>
            <ul>
                <li>Optimize Smac Planner parameters for shorter paths and quicker stabilization.</li>
                <li>Fine-tune MPPI cost weights for better responsiveness to dynamic obstacles.</li>
            </ul>



            <h3>Navigation Performance and Suitability for Safety Scenarios</h3>
            <table>
                <thead>
                    <tr>
                        <th>Global Planner + Local Controller</th>
                        <th>Straight-Line Movement</th>
                        <th>Static Obstacles</th>
                        <th>Dynamic Obstacles</th>
                        <th>Obstacle Clearance</th>
                        <th>Dynamic Obstacle Handling</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>NavFn + DWB</td>
                        <td style="text-align: center;">✅</td>
                        <td style="text-align: center;">✅</td>
                        <td style="text-align: center;">❌</td>
                        <td style="text-align: center;">Good</td>
                        <td style="text-align: center;">Moderate responsiveness</td>
                    </tr>
                    <tr>
                        <td>NavFn + MPPI</td>
                        <td style="text-align: center;">✅</td>
                        <td style="text-align: center;">✅</td>
                        <td style="text-align: center;">✅</td>
                        <td style="text-align: center;">Excellent</td>
                        <td style="text-align: center;">Highly responsive</td>
                    </tr>
                    <tr>
                        <td>NavFn + RPP</td>
                        <td style="text-align: center;">✅</td>
                        <td style="text-align: center;">❌</td>
                        <td style="text-align: center;">❌</td>
                        <td style="text-align: center;">Average (struggles in gaps)</td>
                        <td style="text-align: center;">Slow</td>
                    </tr>
                    <tr>
                        <td>Theta* + RPP</td>
                        <td style="text-align: center;">✅</td>
                        <td style="text-align: center;">✅</td>
                        <td style="text-align: center;">❌</td>
                        <td style="text-align: center;">Excellent</td>
                        <td style="text-align: center;">Slow</td>
                    </tr>
                    <tr>
                        <td>Smac Planner Hybrid + MPPI</td>
                        <td style="text-align: center;">✅</td>
                        <td style="text-align: center;">✅</td>
                        <td style="text-align: center;">❌</td>
                        <td style="text-align: center;">Bad</td>
                        <td style="text-align: center;">Moderate responsiveness</td>
                    </tr>
                </tbody>
            </table>
        
            <div class="note">
                <strong>Key:</strong>
                <ul>
                    <li><strong>✅:</strong> Suitable</li>
                    <li><strong>❌:</strong> Not Suitable</li>
                    <li><strong>Obstacle Clearance:</strong> Describes the ability to navigate close proximities without collisions (e.g., Excellent, Good, Bad).</li>
                    <li><strong>Dynamic Obstacle Handling:</strong> Describes the responsiveness to moving obstacles (e.g., Highly responsive, Moderate, Slow).</li>
                </ul>
            </div>
        
            <div class="important">
                <strong>Important:</strong>
                <p>Controllers perform differently based on drive types (e.g., differential, Ackermann), impacting navigation results. Proper pairing and tuning are crucial for optimal performance.</p>
            </div>
        
            <div class="note">
                <strong>Note:</strong>
                <p>Different drives may give varying results.</p>
            </div>
        
            <h3>Planner Suitability for Different Robot Types</h3>
            <table>
                <thead>
                    <tr>
                        <th>Planner Name</th>
                        <th>Circular Differential</th>
                        <th>Circular Omnidirectional</th>
                        <th>Non-Circular Ackermann</th>
                        <th>Non-Circular Legged</th>
                        <th>Non-Circular Differential/Omnidirectional</th>
                        <th>Arbitrary</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>NavFn Planner</td>
                        <td style="text-align: center;">✅</td>
                        <td style="text-align: center;">✅</td>
                        <td style="text-align: center;">❌</td>
                        <td style="text-align: center;">❌</td>
                        <td style="text-align: center;">❌</td>
                        <td style="text-align: center;">❌</td>
                    </tr>
                    <tr>
                        <td>Smac Planner 2D</td>
                        <td style="text-align: center;">✅</td>
                        <td style="text-align: center;">✅</td>
                        <td style="text-align: center;">❌</td>
                        <td style="text-align: center;">❌</td>
                        <td style="text-align: center;">❌</td>
                        <td style="text-align: center;">❌</td>
                    </tr>
                    <tr>
                        <td>Theta* Planner</td>
                        <td style="text-align: center;">✅</td>
                        <td style="text-align: center;">✅</td>
                        <td style="text-align: center;">❌</td>
                        <td style="text-align: center;">❌</td>
                        <td style="text-align: center;">❌</td>
                        <td style="text-align: center;">❌</td>
                    </tr>
                    <tr>
                        <td>Smac Hybrid-A* Planner</td>
                        <td style="text-align: center;">✅</td>
                        <td style="text-align: center;">✅</td>
                        <td style="text-align: center;">✅</td>
                        <td style="text-align: center;">✅</td>
                        <td style="text-align: center;">✅</td>
                        <td style="text-align: center;">❌</td>
                    </tr>
                    <tr>
                        <td>Smac Lattice Planner</td>
                        <td style="text-align: center;">❌</td>
                        <td style="text-align: center;">❌</td>
                        <td style="text-align: center;">✅</td>
                        <td style="text-align: center;">✅</td>
                        <td style="text-align: center;">✅</td>
                        <td style="text-align: center;">✅</td>
                    </tr>
                </tbody>
            </table>
        
            <div class="note">
                <strong>Key:</strong>
                <ul>
                    <li><strong>✅:</strong> Suitable for this type of robot.</li>
                    <li><strong>❌:</strong> Not suitable for this type of robot.</li>
                </ul>
            </div>
        
            <h3>Controller Suitability for Different Robot Types and Tasks</h3>
            <table>
                <thead>
                    <tr>
                        <th>Controller Name</th>
                        <th>Differential</th>
                        <th>Omnidirectional</th>
                        <th>Ackermann</th>
                        <th>Legged</th>
                        <th>Primary Task</th>
                    </tr>
                </thead>
                <tbody>
                    <tr >
                        <td>DWB Controller</td>
                        <td style="text-align: center;">✅</td>
                        <td style="text-align: center;">✅</td>
                        <td style="text-align: center;">❌</td>
                        <td style="text-align: center;">❌</td>
                        <td style="text-align: center;">Dynamic obstacle avoidance</td>
                    </tr>
                    <tr>
                        <td>MPPI Controller</td>
                        <td style="text-align: center;">✅</td>
                        <td style="text-align: center;">✅</td>
                        <td style="text-align: center;">✅</td>
                        <td style="text-align: center;">✅</td>
                        <td style="text-align: center;">Dynamic obstacle avoidance</td>
                    </tr>
                    <tr>
                        <td>RPP Controller</td>
                        <td style="text-align: center;">✅</td>
                        <td style="text-align: center;">❌</td>
                        <td style="text-align: center;">✅</td>
                        <td style="text-align: center;">✅</td>
                        <td style="text-align: center;">Exact path following</td>
                    </tr>
                    <tr>
                        <td>Rotation Shim</td>
                        <td style="text-align: center;">✅</td>
                        <td style="text-align: center;">✅</td>
                        <td style="text-align: center;">❌</td>
                        <td style="text-align: center;">❌</td>
                        <td style="text-align: center;">Rotate to rough heading</td>
                    </tr>
                    <tr>
                        <td>VP Controller</td>
                        <td style="text-align: center;">✅</td>
                        <td style="text-align: center;">❌</td>
                        <td style="text-align: center;">✅</td>
                        <td style="text-align: center;">✅</td>
                        <td style="text-align: center;">High-speed path tracking</td>
                    </tr>
                </tbody>
            </table>
        
            <div class="note">
                <strong>Key:</strong>
                <ul>
                    <li><strong>✅:</strong> Suitable for this type of robot.</li>
                    <li><strong>❌:</strong> Not suitable for this type of robot.</li>
                </ul>
             </div>

            
             <h2> Conclusion</h2>
            Selecting appropriate planners and controllers is critical for robotic navigation as they must align with the specific task and operational environment. The efficiency of these components varies across different scenarios, such as static and dynamic obstacle navigation, where factors like computational demand, safety, and precision play vital roles. Moreover, tuning parameters in the navigation stack is essential to optimize performance and adaptability. It is, therefore, crucial to comply with safety protocols, especially in environments like retail stores, to ensure safe and efficient human-robot interactions while adhering to regulatory standards and minimizing potential risks.
    </div>
 </body>


</html>
